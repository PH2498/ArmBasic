"""
äººè„¸è¯†åˆ«å…¥å£ï¼šä»æ‘„åƒå¤´å®æ—¶æ£€æµ‹å¹¶è¯†åˆ«å·²çŸ¥äººè„¸ã€‚
å°†å·²çŸ¥äººç‰©ç…§ç‰‡æ”¾å…¥ known_faces æ–‡ä»¶å¤¹ï¼Œæ–‡ä»¶åå³æ˜¾ç¤ºåç§°ï¼ˆå¦‚ å¼ ä¸‰.jpgï¼‰ã€‚

æ³¨æ„ï¼šè¯·è¿è¡Œæœ¬æ–‡ä»¶ï¼ˆrun_face_recognition.pyï¼‰ï¼Œä¸è¦å°†è„šæœ¬å‘½åä¸º face_recognition.pyï¼Œ
å¦åˆ™ä¼šä¸å·²å®‰è£…çš„ face_recognition åº“å†²çªå¯¼è‡´æ— æ³•è¯†åˆ«ã€‚
"""
import cv2
import sys
import os
import numpy as np

# ä½¿ç”¨å·²å®‰è£…çš„ face_recognition åº“ï¼ˆè„šæœ¬åå¿…é¡»ä¸æ˜¯ face_recognition.pyï¼‰
try:
    import face_recognition
    HAS_FACE_RECOGNITION = True
except ImportError:
    HAS_FACE_RECOGNITION = False

try:
    from PIL import Image, ImageDraw, ImageFont
    HAS_PIL = True
except ImportError:
    HAS_PIL = False

SCRIPT_DIR = os.path.dirname(os.path.abspath(__file__))
KNOWN_FACES_DIR = os.path.join(SCRIPT_DIR, "known_faces")
DATA_DIR = os.path.join(SCRIPT_DIR, "data")

# æ€§èƒ½ä¸è¯†åˆ«å‚æ•°
DETECT_SCALE = 0.25  # æ£€æµ‹æ—¶ç¼©å°åˆ° 25% åˆ†è¾¨ç‡ï¼Œå¤§å¹…æå‡å¸§ç‡
DETECT_EVERY_N = 2   # æ¯ N å¸§åšä¸€æ¬¡äººè„¸æ£€æµ‹ï¼Œä¸­é—´å¸§å¤ç”¨ç»“æœ
MATCH_THRESHOLD = 0.65  # è¯†åˆ«é˜ˆå€¼ï¼Œè¶Šå¤§è¶Šå®½æ¾ï¼ˆæ˜“è®¤å‡ºä½†æ˜“è¯¯è¯†ï¼‰


def _get_chinese_font(size=24):
    if not HAS_PIL:
        return None
    for name in ("PingFang.ttc", "SimHei.ttf", "msyh.ttc", "Arial Unicode.ttf"):
        for base in ("/System/Library/Fonts", "/Library/Fonts", "C:/Windows/Fonts", "/usr/share/fonts"):
            path = os.path.join(base, name)
            if os.path.isfile(path):
                try:
                    return ImageFont.truetype(path, size, encoding="utf-8")
                except Exception:
                    pass
    return ImageFont.load_default()


def _draw_text(frame, text, left, top, color_bgr=(0, 255, 0)):
    if not text:
        return
    color_rgb = (color_bgr[2], color_bgr[1], color_bgr[0])
    if any(ord(c) > 127 for c in text) and HAS_PIL:
        font = _get_chinese_font(28)
        pil_img = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))
        draw = ImageDraw.Draw(pil_img)
        y = max(10, top - 5)
        draw.text((left, y), text, color_rgb, font=font)
        frame[:] = cv2.cvtColor(np.array(pil_img), cv2.COLOR_RGB2BGR)
    else:
        cv2.putText(frame, text, (left, max(25, top - 5)), cv2.FONT_HERSHEY_SIMPLEX, 0.8, color_bgr, 2)


def get_camera_index():
    order = [1, 2, 0, 3]
    for index in order:
        cap = cv2.VideoCapture(index)
        if cap.isOpened():
            cap.release()
            return index
    return -1


def load_known_faces():
    known_encodings = []
    known_names = []
    if not HAS_FACE_RECOGNITION:
        return known_encodings, known_names
    if not os.path.isdir(KNOWN_FACES_DIR):
        os.makedirs(KNOWN_FACES_DIR, exist_ok=True)
        return known_encodings, known_names
    exts = (".jpg", ".jpeg", ".png")
    for name in os.listdir(KNOWN_FACES_DIR):
        path = os.path.join(KNOWN_FACES_DIR, name)
        if not os.path.isfile(path) or not name.lower().endswith(exts):
            continue
        label = os.path.splitext(name)[0]
        try:
            img = face_recognition.load_image_file(path)
            # ç”¨ num_jitters=2 å¾—åˆ°æ›´ç¨³çš„ç¼–ç ï¼Œä¾¿äºè¯†åˆ«æˆåŠŸ
            encodings = face_recognition.face_encodings(img, num_jitters=2)
            if encodings:
                known_encodings.append(encodings[0])
                known_names.append(label)
        except Exception as e:
            print(f"âš ï¸ åŠ è½½å·²çŸ¥äººè„¸å¤±è´¥ {name}: {e}")
    return known_encodings, known_names


def _get_haar_cascade_path():
    """è·å– Haar çº§è”è·¯å¾„ï¼šä¼˜å…ˆ OpenCV è‡ªå¸¦ï¼Œå¦åˆ™ä½¿ç”¨é¡¹ç›® data ç›®å½•ä¸‹çš„æ–‡ä»¶"""
    candidates = []
    if getattr(cv2, "data", None) is not None:
        candidates.append(os.path.join(cv2.data.haarcascades, "haarcascade_frontalface_default.xml"))
    cv2_dir = os.path.dirname(cv2.__file__)
    candidates.extend([
        os.path.join(cv2_dir, "data", "haarcascades", "haarcascade_frontalface_default.xml"),
        os.path.join(cv2_dir, "..", "cv2", "data", "haarcascades", "haarcascade_frontalface_default.xml"),
    ])
    # é¡¹ç›®å†…å›é€€è·¯å¾„ï¼ˆæ— å®Œæ•´ OpenCV æ—¶ä½¿ç”¨ï¼‰
    os.makedirs(DATA_DIR, exist_ok=True)
    candidates.append(os.path.join(DATA_DIR, "haarcascade_frontalface_default.xml"))
    for path in candidates:
        path = os.path.normpath(path)
        if os.path.isfile(path):
            return path
    return candidates[-1] if candidates else ""


def detect_faces_opencv(frame):
    cascade_path = _get_haar_cascade_path()
    if not cascade_path or not os.path.isfile(cascade_path):
        return []
    face_cascade = cv2.CascadeClassifier(cascade_path)
    if face_cascade.empty():
        return []
    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.08, minNeighbors=4, minSize=(24, 24))
    return faces


def _draw_cached_boxes(frame, boxes_and_names):
    """ä»…åœ¨ç”»é¢ä¸Šç»˜åˆ¶å·²ç¼“å­˜çš„äººè„¸æ¡†ï¼Œä¸åšæ£€æµ‹ã€‚boxes_and_names: [((left,top,right,bottom), name), ...]"""
    for (left, top, right, bottom), name in boxes_and_names:
        color = (0, 0, 255) if name == "æœªçŸ¥" else (0, 255, 0)
        cv2.rectangle(frame, (left, top), (right, bottom), color, 2)
        _draw_text(frame, name, left, top, color)


def process_frame(frame, known_encodings, known_names):
    """è¿”å› (å¤„ç†åçš„ frame, æœ¬å¸§çš„äººè„¸æ¡†ä¸å§“ååˆ—è¡¨ï¼Œä¾›è·³å¸§æ—¶å¤ç”¨)ã€‚"""
    rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
    h_full, w_full = rgb.shape[:2]
    boxes_and_names = []

    def draw_face_box(left, top, right, bottom, name, color_bgr):
        cv2.rectangle(frame, (left, top), (right, bottom), color_bgr, 2)
        _draw_text(frame, name, left, top, color_bgr)

    if HAS_FACE_RECOGNITION:
        w_small = max(160, int(w_full * DETECT_SCALE))
        h_small = max(120, int(h_full * DETECT_SCALE))
        small = cv2.resize(rgb, (w_small, h_small), interpolation=cv2.INTER_LINEAR)
        scale_x, scale_y = w_full / w_small, h_full / h_small

        face_locations = face_recognition.face_locations(small, model="hog", number_of_times_to_upsample=1)
        face_encodings = face_recognition.face_encodings(small, face_locations)

        for i, (top, right, bottom, left) in enumerate(face_locations):
            left_f = int(left * scale_x)
            right_f = int(right * scale_x)
            top_f = int(top * scale_y)
            bottom_f = int(bottom * scale_y)
            name = "æœªçŸ¥"
            encoding = face_encodings[i] if i < len(face_encodings) else None
            if encoding is not None and known_encodings and known_names:
                distances = face_recognition.face_distance(known_encodings, encoding)
                idx = int(np.argmin(distances))
                if distances[idx] < MATCH_THRESHOLD:
                    name = known_names[idx]
            color = (0, 0, 255) if name == "æœªçŸ¥" else (0, 255, 0)
            draw_face_box(left_f, top_f, right_f, bottom_f, name, color)
            boxes_and_names.append(((left_f, top_f, right_f, bottom_f), name))
        if not face_locations:
            faces = detect_faces_opencv(frame)
            for (x, y, w, h) in faces:
                draw_face_box(x, y, x + w, y + h, "æœªçŸ¥", (0, 0, 255))
                boxes_and_names.append(((x, y, x + w, y + h), "æœªçŸ¥"))
    else:
        faces = detect_faces_opencv(frame)
        for (x, y, w, h) in faces:
            draw_face_box(x, y, x + w, y + h, "Face", (0, 255, 0))
    return frame, boxes_and_names


def recognize_faces_from_frame(frame, known_encodings, known_names):
    """
    å¯¹å•å¸§ç”»é¢åšäººè„¸è¯†åˆ«ï¼Œè¿”å›è¯†åˆ«åˆ°çš„å§“ååˆ—è¡¨ï¼ˆä¾›å…¶ä»–æ¨¡å—å¦‚è¯­éŸ³ AI è°ƒç”¨ï¼‰ã€‚
    è‹¥æœªè¯†åˆ«åˆ°ä»»ä½•äººæˆ–æœªåŒ¹é…åˆ°å·²çŸ¥äººè„¸ï¼Œåˆ—è¡¨ä¸­ä¸º "æœªçŸ¥" æˆ–ä¸ºç©ºã€‚
    """
    if not HAS_FACE_RECOGNITION:
        return []
    rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
    h_full, w_full = rgb.shape[:2]
    w_small = max(160, int(w_full * DETECT_SCALE))
    h_small = max(120, int(h_full * DETECT_SCALE))
    small = cv2.resize(rgb, (w_small, h_small), interpolation=cv2.INTER_LINEAR)
    scale_x, scale_y = w_full / w_small, h_full / h_small
    face_locations = face_recognition.face_locations(small, model="hog", number_of_times_to_upsample=1)
    face_encodings = face_recognition.face_encodings(small, face_locations)
    names = []
    for i, (top, right, bottom, left) in enumerate(face_locations):
        name = "æœªçŸ¥"
        encoding = face_encodings[i] if i < len(face_encodings) else None
        if encoding is not None and known_encodings and known_names:
            distances = face_recognition.face_distance(known_encodings, encoding)
            idx = int(np.argmin(distances))
            if distances[idx] < MATCH_THRESHOLD:
                name = known_names[idx]
        names.append(name)
    return names


def recognize_faces_from_camera(known_faces_dir=None):
    """
    æ‰“å¼€æ‘„åƒå¤´æ‹ä¸€å¸§å¹¶åšäººè„¸è¯†åˆ«ï¼Œè¿”å›å½“å‰ç”»é¢ä¸­è¯†åˆ«åˆ°çš„å§“ååˆ—è¡¨ã€‚
    ä¾› AISpeechInteraction ç­‰æ¨¡å—è°ƒç”¨ï¼Œä¾‹å¦‚ç”¨æˆ·é—®ã€Œæˆ‘æ˜¯è°ã€æ—¶è°ƒç”¨æ­¤å‡½æ•°ã€‚
    known_faces_dir: å·²çŸ¥äººè„¸ç›®å½•ï¼Œé»˜è®¤ä½¿ç”¨ FaceRecognitionModule/known_facesã€‚
    """
    if known_faces_dir is None:
        known_faces_dir = KNOWN_FACES_DIR
    # ä¸´æ—¶æ”¹ç”¨æŒ‡å®šç›®å½•åŠ è½½å·²çŸ¥äººè„¸ï¼ˆè‹¥ä¸å½“å‰ SCRIPT_DIR ä¸€è‡´åˆ™ç”¨ç°æœ‰é€»è¾‘ï¼‰
    if os.path.normpath(known_faces_dir) != os.path.normpath(KNOWN_FACES_DIR):
        known_encodings, known_names = [], []
        if HAS_FACE_RECOGNITION and os.path.isdir(known_faces_dir):
            exts = (".jpg", ".jpeg", ".png")
            for name in os.listdir(known_faces_dir):
                path = os.path.join(known_faces_dir, name)
                if not os.path.isfile(path) or not name.lower().endswith(exts):
                    continue
                label = os.path.splitext(name)[0]
                try:
                    img = face_recognition.load_image_file(path)
                    encodings = face_recognition.face_encodings(img, num_jitters=2)
                    if encodings:
                        known_encodings.append(encodings[0])
                        known_names.append(label)
                except Exception:
                    pass
    else:
        known_encodings, known_names = load_known_faces()
    idx = get_camera_index()
    if idx < 0:
        return []
    cap = cv2.VideoCapture(idx)
    for _ in range(5):
        cap.read()
    ret, frame = cap.read()
    cap.release()
    if not ret or frame is None:
        return []
    return recognize_faces_from_frame(frame, known_encodings, known_names)


def main():
    print("---------- ä¾èµ–æ£€æŸ¥ ----------")
    cascade_path = _get_haar_cascade_path()
    cascade_ok = bool(cascade_path and os.path.isfile(cascade_path))
    print(f"  face_recognition åº“: {'å·²å®‰è£…' if HAS_FACE_RECOGNITION else 'æœªå®‰è£…'}")
    print(f"  OpenCV äººè„¸æ¨¡å‹: {'å·²æ‰¾åˆ°' if cascade_ok else 'æœªæ‰¾åˆ°'}")
    if cascade_path:
        print(f"    è·¯å¾„: {cascade_path}")
    if not cascade_ok:
        print("  âš ï¸ è¯·æ‰§è¡Œä»¥ä¸‹ä»»ä¸€æ–¹å¼ï¼š")
        print("     1) pip uninstall opencv-python-headless; pip install opencv-python")
        print("     2) æˆ–ä¸‹è½½æ¨¡å‹åˆ° data ç›®å½•: è§ README æˆ–è¿è¡Œ download_cascade.py")

    if not HAS_FACE_RECOGNITION:
        print("ğŸ’¡ å®‰è£…äººè„¸è¯†åˆ«åº“: pip install face_recognition")
    known_encodings, known_names = load_known_faces()
    if known_encodings:
        print(f"âœ… å·²åŠ è½½ {len(known_names)} ä¸ªå·²çŸ¥äººè„¸: {', '.join(known_names)}")
    else:
        print("ğŸ’¡ åœ¨ known_faces ä¸­æ”¾å…¥å·²çŸ¥äººç‰©ç…§ç‰‡å³å¯è¯†åˆ«")
    print("------------------------------")

    camera_idx = get_camera_index()
    if camera_idx == -1:
        print("âŒ æœªæ£€æµ‹åˆ°å¯ç”¨æ‘„åƒå¤´")
        sys.exit(1)

    cap = cv2.VideoCapture(camera_idx)
    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)
    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)
    win_name = "Face Recognition (q to quit)"
    cv2.namedWindow(win_name, cv2.WINDOW_NORMAL)
    cv2.resizeWindow(win_name, 1280, 720)
    for _ in range(5):
        cap.read()

    print(f"âœ… æˆåŠŸè¿æ¥æ‘„åƒå¤´ï¼Œç´¢å¼•ï¼š{camera_idx}")
    print("ğŸ’¡ æŒ‰ 'q' é”®é€€å‡ºç¨‹åº")

    first_frame_diagnostic_done = False
    frame_count = 0
    cached_boxes = []
    while True:
        ret, frame = cap.read()
        if not ret or frame is None:
            print("âŒ æ— æ³•è¯»å–æ‘„åƒå¤´ç”»é¢")
            break
        try:
            if not first_frame_diagnostic_done and frame is not None:
                n_cv = len(detect_faces_opencv(frame))
                n_hog = 0
                if HAS_FACE_RECOGNITION:
                    rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                    n_hog = len(face_recognition.face_locations(rgb, model="hog", number_of_times_to_upsample=1))
                print(f"ğŸ“· é¦–å¸§æ£€æµ‹: face_recognition={n_hog} äººè„¸, OpenCV={n_cv} äººè„¸")
                first_frame_diagnostic_done = True
            # æ¯ DETECT_EVERY_N å¸§åšä¸€æ¬¡å®Œæ•´æ£€æµ‹ï¼Œä¸­é—´å¸§åªå¤ç”¨ä¸Šä¸€å¸§çš„æ¡†ï¼Œæå‡å¸§ç‡
            if frame_count % DETECT_EVERY_N == 0 or not cached_boxes:
                frame, cached_boxes = process_frame(frame, known_encodings, known_names)
            else:
                _draw_cached_boxes(frame, cached_boxes)
            frame_count += 1
        except Exception as e:
            print(f"âš ï¸ å¤„ç†ç”»é¢æ—¶å‡ºé”™: {e}")
        h, w = frame.shape[:2]
        if w < 640 or h < 480:
            frame = cv2.resize(frame, (1280, 720), interpolation=cv2.INTER_LINEAR)
        cv2.imshow(win_name, frame)
        if cv2.waitKey(1) & 0xFF == ord("q"):
            break

    cap.release()
    cv2.destroyAllWindows()


if __name__ == "__main__":
    main()
